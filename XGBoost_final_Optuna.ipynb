{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37a47f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw merged shape: (59526, 120)\n",
      "Spike-in genes detected: 97\n",
      "After removing spike-ins: (59429, 120)\n",
      "Genes zero everywhere: 14289\n",
      "After removing all-zero genes: (45140, 120)\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Load count matrix using TPM\n",
    "data_path = '/Users/esrataner/Documents/DATA1030/count_matrix_120'\n",
    "file_list = [f for f in os.listdir(data_path) if f.endswith('.tsv')]\n",
    "\n",
    "def read_tpm_file(filename):\n",
    "    df = pd.read_csv(os.path.join(data_path, filename), sep='\\t',\n",
    "                     usecols=['gene_id', 'TPM'])\n",
    "    df = df.set_index('gene_id')\n",
    "    sample_id = filename.replace('.tsv', '')\n",
    "    df.columns = [sample_id]\n",
    "    return df\n",
    "\n",
    "dfs = [read_tpm_file(f) for f in file_list]\n",
    "merged = pd.concat(dfs, axis=1)  # genes × samples\n",
    "print(\"Raw merged shape:\", merged.shape)\n",
    "\n",
    "# 2. remove all spike-in genes \n",
    "# these are technical control genes - not needed for ML \n",
    "spikein_mask = merged.index.str.lower().str.contains(\n",
    "    \"spikein|ercc\"\n",
    ")\n",
    "\n",
    "print(\"Spike-in genes detected:\", spikein_mask.sum())\n",
    "\n",
    "merged = merged.loc[~spikein_mask]\n",
    "print(\"After removing spike-ins:\", merged.shape)\n",
    "\n",
    "# 3. Remove all-zero genes\n",
    "zero_across_all = (merged == 0).all(axis=1)\n",
    "print(\"Genes zero everywhere:\", zero_across_all.sum())\n",
    "\n",
    "expr = merged[~zero_across_all]\n",
    "print(\"After removing all-zero genes:\", expr.shape)\n",
    "\n",
    "# 4. log1p(TPM) transform — biological normalization\n",
    "expr_log = np.log1p(expr)\n",
    "\n",
    "# NOTE: try graphing log1p and log \n",
    "# depends on if data is close to zero or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306d6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded metadata shape: (1220, 5)\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "\n",
    "meta = pd.read_csv(\n",
    "    '/Users/esrataner/Documents/DATA1030/tsv/experiment_report_2025_120.tsv',\n",
    "    sep='\\t', skiprows=1\n",
    ")\n",
    "\n",
    "# extract sex\n",
    "meta['Sex'] = meta['Biosample summary'].str.extract(r'(?i)\\b(female|male)\\b')\n",
    "meta['Sex'] = meta['Sex'].str.lower()\n",
    "\n",
    "# parse numeric age\n",
    "def parse_age(a):\n",
    "    if pd.isna(a):\n",
    "        return None\n",
    "    nums = re.findall(r'\\d+', str(a))\n",
    "    return int(nums[0]) if nums else None\n",
    "\n",
    "meta['Age'] = meta['Biosample age'].apply(parse_age)\n",
    "\n",
    "# Age bins\n",
    "def age_bin(x):\n",
    "    if pd.isna(x): return None\n",
    "    if x < 65: return \"60-64\"\n",
    "    if x < 70: return \"65-69\"\n",
    "    if x < 75: return \"70-74\"\n",
    "    if x < 80: return \"75-79\"\n",
    "    if x < 85: return \"80-84\"\n",
    "    if x < 90: return \"85-89\"\n",
    "    return \"90+\"\n",
    "\n",
    "meta['Age_Ordinal'] = meta['Age'].apply(age_bin)\n",
    "\n",
    "age_order = [\"60-64\",\"65-69\",\"70-74\",\"75-79\",\"80-84\",\"85-89\",\"90+\"]\n",
    "meta['Age_Ordinal'] = pd.Categorical(\n",
    "    meta['Age_Ordinal'], categories=age_order, ordered=True\n",
    ")\n",
    "\n",
    "# FIX!!  Extract *all* ENCFF file IDs (not just first)\n",
    "# Find ALL ENCFF IDs\n",
    "meta['File_IDs'] = meta['Files'].str.findall(r'ENCFF\\w+')\n",
    "\n",
    "# Expand metadata so each row contains ONE ENCFF ID\n",
    "meta_expanded = meta.explode('File_IDs')\n",
    "\n",
    "# Keep only relevant fields\n",
    "meta_expanded = meta_expanded[\n",
    "    ['Accession', 'Sex', 'Age_Ordinal', 'Biosample accession', 'File_IDs']\n",
    "]\n",
    "\n",
    "# Drop rows missing file IDs\n",
    "meta_expanded = meta_expanded.dropna(subset=['File_IDs'])\n",
    "\n",
    "print(\"Expanded metadata shape:\", meta_expanded.shape)\n",
    "# Expanded metadata shape: (1220, 5)\n",
    "\n",
    "# exp \n",
    "# in the raw ENCODE metadata, each biological sample (ENCSR) has multiple ENCFF files \n",
    "# (technical sequencing files: BAMs, fastqs, quantifications, etc)\n",
    "\n",
    "# After expanding, u get 1 row per ENCFF file\n",
    "# so if each ENCSR has ~10 ENCFF files ->  120 biological samples become ~1220 rows.\n",
    "# so 1220 is NOT 120 samples - it is technical files, NOT samples\n",
    "\n",
    "# MOST IMPORTANTLY - do NOT need GroupShuffleSplit\n",
    "# 1. each ENCSR is represented only once\n",
    "# 2. no ENCFF technical replicates remain#\n",
    "# 3. df_full has 1 row per biological sample\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched metadata rows: (120, 5)\n",
      "Replicate sample accessions: []\n",
      "Expression shape after removing replicates: (45140, 120)\n",
      "Metadata shape after removing replicates: (120, 5)\n",
      "Final merged dataset shape: (120, 45143)\n",
      "             13023     26893  30031  30958     30964  ENSG00000000003.14  \\\n",
      "Accession                                                                  \n",
      "ENCSR800PJQ    0.0  0.506818    0.0    0.0  0.000000            1.348073   \n",
      "ENCSR133PLR    0.0  0.000000    0.0    0.0  2.324347            1.340250   \n",
      "ENCSR418WMG    0.0  0.000000    0.0    0.0  0.000000            1.181727   \n",
      "ENCSR013HWB    0.0  0.438255    0.0    0.0  0.000000            1.313724   \n",
      "ENCSR693KOP    0.0  0.000000    0.0    0.0  0.000000            1.081805   \n",
      "\n",
      "             ENSG00000000005.5  ENSG00000000419.12  ENSG00000000457.13  \\\n",
      "Accession                                                                \n",
      "ENCSR800PJQ           0.000000            2.157559            1.444563   \n",
      "ENCSR133PLR           0.122218            2.150599            1.479329   \n",
      "ENCSR418WMG           0.000000            2.149434            1.545433   \n",
      "ENCSR013HWB           0.029559            1.873339            1.095273   \n",
      "ENCSR693KOP           0.000000            2.119863            1.105257   \n",
      "\n",
      "             ENSG00000000460.16  ...  ENSG00000285986.1  ENSG00000285987.1  \\\n",
      "Accession                        ...                                         \n",
      "ENCSR800PJQ            1.297463  ...                0.0           0.029559   \n",
      "ENCSR133PLR            1.068153  ...                0.0           0.067659   \n",
      "ENCSR418WMG            1.108563  ...                0.0           0.000000   \n",
      "ENCSR013HWB            1.111858  ...                0.0           0.104360   \n",
      "ENCSR693KOP            0.916291  ...                0.0           0.019803   \n",
      "\n",
      "             ENSG00000285988.1  ENSG00000285990.1  ENSG00000285991.1  \\\n",
      "Accession                                                              \n",
      "ENCSR800PJQ                0.0           0.000000           0.165514   \n",
      "ENCSR133PLR                0.0           0.000000           0.182322   \n",
      "ENCSR418WMG                0.0           0.364643           0.067659   \n",
      "ENCSR013HWB                0.0           0.000000           0.215111   \n",
      "ENCSR693KOP                0.0           0.000000           0.058269   \n",
      "\n",
      "             ENSG00000285993.1  ENSG00000285994.1     Sex  Age_Ordinal  \\\n",
      "Accession                                                                \n",
      "ENCSR800PJQ                0.0           0.806476  female          90+   \n",
      "ENCSR133PLR                0.0           0.770108    male        85-89   \n",
      "ENCSR418WMG                0.0           0.732368    male        85-89   \n",
      "ENCSR013HWB                0.0           0.647103  female        85-89   \n",
      "ENCSR693KOP                0.0           0.470004  female        85-89   \n",
      "\n",
      "             Biosample accession  \n",
      "Accession                         \n",
      "ENCSR800PJQ          ENCBS159MAA  \n",
      "ENCSR133PLR          ENCBS634VGA  \n",
      "ENCSR418WMG          ENCBS589OUP  \n",
      "ENCSR013HWB          ENCBS046CJD  \n",
      "ENCSR693KOP          ENCBS048EXC  \n",
      "\n",
      "[5 rows x 45143 columns]\n"
     ]
    }
   ],
   "source": [
    "# cell 3 \n",
    "\n",
    "# List of ENCFF IDs found in expression matrix\n",
    "expr_samples = expr_log.columns.tolist()\n",
    "\n",
    "# Match metadata rows where File_IDs map to expression samples\n",
    "meta_matched = meta_expanded[meta_expanded['File_IDs'].isin(expr_samples)].copy()\n",
    "print(\"Matched metadata rows:\", meta_matched.shape)\n",
    "\n",
    "# Step 1: Relabel expression matrix columns (ENCFF → ENCSR)\n",
    "rename_dict = dict(zip(meta_matched['File_IDs'], meta_matched['Accession']))\n",
    "expr_labeled = expr_log.rename(columns=rename_dict)\n",
    "\n",
    "# Step 2: Identify replicate sample IDs (appear twice)\n",
    "replicate_accessions = expr_labeled.columns[\n",
    "    expr_labeled.columns.duplicated()\n",
    "].unique()\n",
    "\n",
    "print(\"Replicate sample accessions:\", replicate_accessions.tolist())\n",
    "\n",
    "# Step 3: DROP the replicate sample completely\n",
    "expr_no_reps = expr_labeled.drop(columns=list(replicate_accessions))\n",
    "meta_no_reps = meta_matched[\n",
    "    ~meta_matched['Accession'].isin(replicate_accessions)\n",
    "].copy()\n",
    "\n",
    "print(\"Expression shape after removing replicates:\", expr_no_reps.shape)\n",
    "print(\"Metadata shape after removing replicates:\", meta_no_reps.shape)\n",
    "\n",
    "# Step 4: Align expression with metadata\n",
    "expr_T = expr_no_reps.T\n",
    "expr_T.index.name = 'Accession'\n",
    "expr_T = expr_T.reset_index()\n",
    "\n",
    "# Deduplicate final metadata\n",
    "meta_unique = meta_no_reps.drop_duplicates(subset=['Accession'])\n",
    "\n",
    "# Step 5: Merge into final ML-ready dataset\n",
    "df_full = expr_T.merge(\n",
    "    meta_unique.drop(columns=['File_IDs']),\n",
    "    on='Accession',\n",
    "    how='inner'\n",
    ").set_index('Accession')\n",
    "\n",
    "print(\"Final merged dataset shape:\", df_full.shape)\n",
    "print(df_full.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f189a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Splits:\n",
      "Train: (84, 45141) Target: (84,)\n",
      "Val:   (18, 45141) Target: (18,)\n",
      "Test:  (18, 45141) Target: (18,)\n"
     ]
    }
   ],
   "source": [
    "# cell 4 \n",
    "\n",
    "# TRAIN / VAL / TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (1) Define features + target\n",
    "X = df_full.drop(columns=[\"Sex\", \"Biosample accession\"]) #string carried over \n",
    "y = df_full[\"Sex\"].map({\"female\": 0, \"male\": 1}).astype(int)\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "# (2) First split: Train vs Temp (Val+Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# (3) Split Temp into Validation + Test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Print shapes\n",
    "print(\"Dataset Splits:\")\n",
    "print(\"Train:\", X_train.shape, \"Target:\", y_train.shape)\n",
    "print(\"Val:  \", X_val.shape,   \"Target:\", y_val.shape)\n",
    "print(\"Test: \", X_test.shape,  \"Target:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight (initial split) = 3.0000\n",
      "[0]\tvalidation_0-logloss:0.66791\n",
      "[1]\tvalidation_0-logloss:0.64257\n",
      "[2]\tvalidation_0-logloss:0.63504\n",
      "[3]\tvalidation_0-logloss:0.62314\n",
      "[4]\tvalidation_0-logloss:0.59624\n",
      "[5]\tvalidation_0-logloss:0.59290\n",
      "[6]\tvalidation_0-logloss:0.58634\n",
      "[7]\tvalidation_0-logloss:0.56521\n",
      "[8]\tvalidation_0-logloss:0.55086\n",
      "[9]\tvalidation_0-logloss:0.53728\n",
      "[10]\tvalidation_0-logloss:0.53500\n",
      "[11]\tvalidation_0-logloss:0.51820\n",
      "[12]\tvalidation_0-logloss:0.49902\n",
      "[13]\tvalidation_0-logloss:0.48449\n",
      "[14]\tvalidation_0-logloss:0.49170\n",
      "[15]\tvalidation_0-logloss:0.48403\n",
      "[16]\tvalidation_0-logloss:0.47638\n",
      "[17]\tvalidation_0-logloss:0.47090\n",
      "[18]\tvalidation_0-logloss:0.46432\n",
      "[19]\tvalidation_0-logloss:0.45436\n",
      "[20]\tvalidation_0-logloss:0.44672\n",
      "[21]\tvalidation_0-logloss:0.43318\n",
      "[22]\tvalidation_0-logloss:0.42612\n",
      "[23]\tvalidation_0-logloss:0.43208\n",
      "[24]\tvalidation_0-logloss:0.42850\n",
      "[25]\tvalidation_0-logloss:0.42556\n",
      "[26]\tvalidation_0-logloss:0.41823\n",
      "[27]\tvalidation_0-logloss:0.41624\n",
      "[28]\tvalidation_0-logloss:0.42221\n",
      "[29]\tvalidation_0-logloss:0.41511\n",
      "[30]\tvalidation_0-logloss:0.40448\n",
      "[31]\tvalidation_0-logloss:0.40535\n",
      "[32]\tvalidation_0-logloss:0.40883\n",
      "[33]\tvalidation_0-logloss:0.40148\n",
      "[34]\tvalidation_0-logloss:0.39456\n",
      "[35]\tvalidation_0-logloss:0.39345\n",
      "[36]\tvalidation_0-logloss:0.39397\n",
      "[37]\tvalidation_0-logloss:0.39476\n",
      "[38]\tvalidation_0-logloss:0.38734\n",
      "[39]\tvalidation_0-logloss:0.38342\n",
      "[40]\tvalidation_0-logloss:0.38477\n",
      "[41]\tvalidation_0-logloss:0.37943\n",
      "[42]\tvalidation_0-logloss:0.38307\n",
      "[43]\tvalidation_0-logloss:0.37988\n",
      "[44]\tvalidation_0-logloss:0.37776\n",
      "[45]\tvalidation_0-logloss:0.37416\n",
      "[46]\tvalidation_0-logloss:0.36711\n",
      "[47]\tvalidation_0-logloss:0.36467\n",
      "[48]\tvalidation_0-logloss:0.36717\n",
      "[49]\tvalidation_0-logloss:0.37046\n",
      "[50]\tvalidation_0-logloss:0.36879\n",
      "[51]\tvalidation_0-logloss:0.36753\n",
      "[52]\tvalidation_0-logloss:0.36589\n",
      "[53]\tvalidation_0-logloss:0.36707\n",
      "[54]\tvalidation_0-logloss:0.36953\n",
      "[55]\tvalidation_0-logloss:0.36817\n",
      "[56]\tvalidation_0-logloss:0.37164\n",
      "[57]\tvalidation_0-logloss:0.37126\n",
      "Best n_estimators from early stopping: 47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#  scale_pos_weight\n",
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "print(f\"scale_pos_weight (initial split) = {scale_pos_weight:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "gene_cols = [c for c in X_train.columns if c != \"Age_Ordinal\"]\n",
    "\n",
    "def make_preprocessor():\n",
    "    \"\"\"Fresh ColumnTransformer each time (no leakage).\"\"\"\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), gene_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"Age_Ordinal\"])\n",
    "    ])\n",
    "\n",
    "\n",
    "# early-stopping model to get best_iter\n",
    "\n",
    "pre_early = make_preprocessor()\n",
    "pre_early.fit(X_train)\n",
    "\n",
    "X_train_trans = pre_early.transform(X_train)\n",
    "X_val_trans   = pre_early.transform(X_val)\n",
    "\n",
    "early_model = XGBClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.2,\n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    early_stopping_rounds=10,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "early_model.fit(\n",
    "    X_train_trans,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_trans, y_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_iter = early_model.best_iteration\n",
    "print(\"Best n_estimators from early stopping:\", best_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061682bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def make_xgb_pipeline(n_estimators, scale_pos_weight, random_state=42):\n",
    "    \"\"\"XGB pipeline with preprocessor inside (no leakage across CV).\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"preprocessor\", make_preprocessor()),\n",
    "        (\"model\", XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=random_state,\n",
    "            n_estimators=n_estimators,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        ))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-12 03:09:26,578] A new study created in memory with name: no-name-71ab1c6b-0cc1-4f5e-8759-d7d058743f56\n",
      "[I 2025-12-12 03:09:30,886] Trial 0 finished with value: 0.6961694677871149 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.08078644467911282, 'model__subsample': 0.6218543331143649, 'model__colsample_bytree': 0.4008170769591276, 'model__reg_alpha': 0.503425676723821, 'model__reg_lambda': 0.10440984448346191}. Best is trial 0 with value: 0.6961694677871149.\n",
      "[I 2025-12-12 03:09:34,543] Trial 1 finished with value: 0.6848389355742297 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.05280513816669777, 'model__subsample': 0.776093360161199, 'model__colsample_bytree': 0.3893225383905389, 'model__reg_alpha': 1.28269762470195, 'model__reg_lambda': 1.2047254487839938}. Best is trial 0 with value: 0.6961694677871149.\n",
      "[I 2025-12-12 03:09:38,220] Trial 2 finished with value: 0.7304761904761905 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.013976830731314557, 'model__subsample': 0.6093963736575735, 'model__colsample_bytree': 0.37175670101537883, 'model__reg_alpha': 0.880910541123044, 'model__reg_lambda': 2.8025492630376947}. Best is trial 2 with value: 0.7304761904761905.\n",
      "[I 2025-12-12 03:09:41,408] Trial 3 finished with value: 0.7010714285714286 and parameters: {'model__max_depth': 6, 'model__learning_rate': 0.06841960599013772, 'model__subsample': 0.765117263862032, 'model__colsample_bytree': 0.16937604051668229, 'model__reg_alpha': 2.7841327894460486, 'model__reg_lambda': 2.6486852319978977}. Best is trial 2 with value: 0.7304761904761905.\n",
      "[I 2025-12-12 03:09:43,948] Trial 4 finished with value: 0.7631535947712418 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.07457411577317957, 'model__subsample': 0.8958825944398003, 'model__colsample_bytree': 0.21289084401330902, 'model__reg_alpha': 2.308046635929779, 'model__reg_lambda': 1.7118475101257093}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:09:47,228] Trial 5 finished with value: 0.7067921784098254 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.057331006545594095, 'model__subsample': 0.8844435277940269, 'model__colsample_bytree': 0.594566012380078, 'model__reg_alpha': 1.6127416992533645, 'model__reg_lambda': 2.197687785083563}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:09:50,041] Trial 6 finished with value: 0.7446493212669683 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.09802135901853767, 'model__subsample': 0.8903058030416746, 'model__colsample_bytree': 0.32547779286266765, 'model__reg_alpha': 2.242148454621376, 'model__reg_lambda': 2.9806953877384497}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:09:53,182] Trial 7 finished with value: 0.6739285714285714 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.03731401117879388, 'model__subsample': 0.6127140884629209, 'model__colsample_bytree': 0.1395568214180535, 'model__reg_alpha': 1.0340553558531487, 'model__reg_lambda': 2.4964401196577426}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:09:55,674] Trial 8 finished with value: 0.6999603174603174 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.036475133332040346, 'model__subsample': 0.6048860629524863, 'model__colsample_bytree': 0.2774453416659717, 'model__reg_alpha': 1.6447834458308632, 'model__reg_lambda': 1.108451325061591}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:09:59,243] Trial 9 finished with value: 0.6580020796197267 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.06794967342963718, 'model__subsample': 0.9471014310695327, 'model__colsample_bytree': 0.5716903916421595, 'model__reg_alpha': 0.12574607450850728, 'model__reg_lambda': 0.9248107016078929}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:10:01,148] Trial 10 finished with value: 0.6673484848484849 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.0932289962384232, 'model__subsample': 0.9728670720602217, 'model__colsample_bytree': 0.23733416405987962, 'model__reg_alpha': 2.767541646216087, 'model__reg_lambda': 1.8275996670790713}. Best is trial 4 with value: 0.7631535947712418.\n",
      "[I 2025-12-12 03:10:03,696] Trial 11 finished with value: 0.76508658008658 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.098421437973886, 'model__subsample': 0.8655754733394786, 'model__colsample_bytree': 0.24745941044195302, 'model__reg_alpha': 2.2348235261013984, 'model__reg_lambda': 1.8648643321217733}. Best is trial 11 with value: 0.76508658008658.\n",
      "[I 2025-12-12 03:10:05,490] Trial 12 finished with value: 0.7733333333333333 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.08440513528562332, 'model__subsample': 0.8476394640168936, 'model__colsample_bytree': 0.2038118660237095, 'model__reg_alpha': 2.20358911895463, 'model__reg_lambda': 1.8375319723687307}. Best is trial 12 with value: 0.7733333333333333.\n",
      "[I 2025-12-12 03:10:07,240] Trial 13 finished with value: 0.7379826546003017 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.08814575771486693, 'model__subsample': 0.8260927800854437, 'model__colsample_bytree': 0.10153055311518404, 'model__reg_alpha': 2.0741053219525787, 'model__reg_lambda': 2.1190068986285975}. Best is trial 12 with value: 0.7733333333333333.\n",
      "[I 2025-12-12 03:10:09,890] Trial 14 finished with value: 0.6894047619047619 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.08454969010065526, 'model__subsample': 0.6997655676636517, 'model__colsample_bytree': 0.29793843748338256, 'model__reg_alpha': 1.9838823208506007, 'model__reg_lambda': 1.48704975630671}. Best is trial 12 with value: 0.7733333333333333.\n",
      "[I 2025-12-12 03:10:11,978] Trial 15 finished with value: 0.6942532467532467 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.09956731400023479, 'model__subsample': 0.835387084197041, 'model__colsample_bytree': 0.4668820915015057, 'model__reg_alpha': 2.5728089519841446, 'model__reg_lambda': 0.49415664760433153}. Best is trial 12 with value: 0.7733333333333333.\n",
      "[I 2025-12-12 03:10:13,850] Trial 16 finished with value: 0.7065540831717303 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.07898633938106453, 'model__subsample': 0.72864370354894, 'model__colsample_bytree': 0.20887441698559778, 'model__reg_alpha': 2.9815164560183183, 'model__reg_lambda': 2.0728096026955236}. Best is trial 12 with value: 0.7733333333333333.\n",
      "[I 2025-12-12 03:10:16,540] Trial 17 finished with value: 0.7941666666666667 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.05889453991786492, 'model__subsample': 0.8490208346556942, 'model__colsample_bytree': 0.25051515383470835, 'model__reg_alpha': 1.94093147720719, 'model__reg_lambda': 1.572587419802435}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:19,540] Trial 18 finished with value: 0.7149068415244886 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.04735959286492998, 'model__subsample': 0.9317777612129619, 'model__colsample_bytree': 0.4511099556882351, 'model__reg_alpha': 1.822034503582948, 'model__reg_lambda': 1.433912470646652}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:22,269] Trial 19 finished with value: 0.7125793650793651 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.016274949374269473, 'model__subsample': 0.9942232575091788, 'model__colsample_bytree': 0.17052721103314766, 'model__reg_alpha': 1.3974574569186649, 'model__reg_lambda': 0.6117442093159209}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:25,585] Trial 20 finished with value: 0.7126960784313725 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.06296096085136416, 'model__subsample': 0.8105612639669976, 'model__colsample_bytree': 0.32210774065657805, 'model__reg_alpha': 2.606125610071511, 'model__reg_lambda': 1.2669579003142066}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:27,595] Trial 21 finished with value: 0.699551282051282 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.09393285955485739, 'model__subsample': 0.853110884632011, 'model__colsample_bytree': 0.2565563809431644, 'model__reg_alpha': 2.351262826593006, 'model__reg_lambda': 1.7781982354434223}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:29,404] Trial 22 finished with value: 0.7933333333333333 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.0874105404171363, 'model__subsample': 0.8520699049439322, 'model__colsample_bytree': 0.19661641380946143, 'model__reg_alpha': 1.9337026363496472, 'model__reg_lambda': 2.3670390055361046}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:32,018] Trial 23 finished with value: 0.733538961038961 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.07217912447435487, 'model__subsample': 0.7903014557423456, 'model__colsample_bytree': 0.1888930643953053, 'model__reg_alpha': 1.8982207486825944, 'model__reg_lambda': 2.417505995875124}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:33,902] Trial 24 finished with value: 0.7744047619047618 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.04536908477270964, 'model__subsample': 0.9140344921484599, 'model__colsample_bytree': 0.12457372632595518, 'model__reg_alpha': 1.68622492868846, 'model__reg_lambda': 2.318721024312333}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:36,785] Trial 25 finished with value: 0.7095238095238096 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.0383601897288091, 'model__subsample': 0.9256279829043803, 'model__colsample_bytree': 0.1103157788897463, 'model__reg_alpha': 1.2763695249343279, 'model__reg_lambda': 2.4846883567053704}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:38,584] Trial 26 finished with value: 0.7653361344537816 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.027417520277086504, 'model__subsample': 0.9172375693896578, 'model__colsample_bytree': 0.1483334264916725, 'model__reg_alpha': 1.7652579873281882, 'model__reg_lambda': 2.285491995694572}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:41,068] Trial 27 finished with value: 0.7398202614379086 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.04590273737439058, 'model__subsample': 0.7429791201526554, 'model__colsample_bytree': 0.13600258189773454, 'model__reg_alpha': 1.5239878232875492, 'model__reg_lambda': 2.8623611404575247}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:44,038] Trial 28 finished with value: 0.6975 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.06018476898526654, 'model__subsample': 0.9655512201291426, 'model__colsample_bytree': 0.23194597570977873, 'model__reg_alpha': 0.9612541419045496, 'model__reg_lambda': 2.0021759090963647}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:46,186] Trial 29 finished with value: 0.7492647058823529 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.024636497920882655, 'model__subsample': 0.8728798669457827, 'model__colsample_bytree': 0.27932526018091575, 'model__reg_alpha': 0.6707543850730251, 'model__reg_lambda': 0.1765779627087778}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:49,060] Trial 30 finished with value: 0.7127056277056277 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.050832481995338755, 'model__subsample': 0.6928070778511636, 'model__colsample_bytree': 0.4298527613477313, 'model__reg_alpha': 1.1769884994745219, 'model__reg_lambda': 1.5735351591202547}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:50,861] Trial 31 finished with value: 0.7394047619047619 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.07910655288328675, 'model__subsample': 0.8309048901787482, 'model__colsample_bytree': 0.1850904278969624, 'model__reg_alpha': 2.0743747456412214, 'model__reg_lambda': 2.341762590767027}. Best is trial 17 with value: 0.7941666666666667.\n",
      "[I 2025-12-12 03:10:52,662] Trial 32 finished with value: 0.8053361344537816 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.08926149149187426, 'model__subsample': 0.8476568298690188, 'model__colsample_bytree': 0.20722262300954447, 'model__reg_alpha': 1.714534645592426, 'model__reg_lambda': 1.9877422958522308}. Best is trial 32 with value: 0.8053361344537816.\n",
      "[I 2025-12-12 03:10:55,173] Trial 33 finished with value: 0.7445028011204482 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.04088385220171327, 'model__subsample': 0.9074132441176892, 'model__colsample_bytree': 0.1498192779933033, 'model__reg_alpha': 1.6855805700465767, 'model__reg_lambda': 2.6911132147350485}. Best is trial 32 with value: 0.8053361344537816.\n",
      "[I 2025-12-12 03:10:56,902] Trial 34 finished with value: 0.8219047619047618 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.030288285427863063, 'model__subsample': 0.8148415329961067, 'model__colsample_bytree': 0.12755780273568829, 'model__reg_alpha': 1.4501884946710066, 'model__reg_lambda': 1.9567884838366505}. Best is trial 34 with value: 0.8219047619047618.\n",
      "[I 2025-12-12 03:10:59,456] Trial 35 finished with value: 0.8254761904761905 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.02594529453035626, 'model__subsample': 0.8097992181431611, 'model__colsample_bytree': 0.16799580159890665, 'model__reg_alpha': 1.4061736047358249, 'model__reg_lambda': 1.6099873145029557}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:02,451] Trial 36 finished with value: 0.6979341736694678 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.02874896852964785, 'model__subsample': 0.8004085758054524, 'model__colsample_bytree': 0.35399445482315944, 'model__reg_alpha': 1.4920478297845958, 'model__reg_lambda': 1.5734333365972804}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:04,926] Trial 37 finished with value: 0.7229761904761904 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.018486457043527006, 'model__subsample': 0.7737403637728085, 'model__colsample_bytree': 0.16317347588009737, 'model__reg_alpha': 0.7038125035272066, 'model__reg_lambda': 1.2733521974443966}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:07,713] Trial 38 finished with value: 0.6908608058608058 and parameters: {'model__max_depth': 6, 'model__learning_rate': 0.03224207129359449, 'model__subsample': 0.7443073132022646, 'model__colsample_bytree': 0.2220750396032192, 'model__reg_alpha': 1.157875433333999, 'model__reg_lambda': 1.988802596925286}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:10,349] Trial 39 finished with value: 0.7146008403361345 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.053845683701560954, 'model__subsample': 0.8089073634850029, 'model__colsample_bytree': 0.26859739315872083, 'model__reg_alpha': 1.4009429064411985, 'model__reg_lambda': 1.0185718847245}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:13,886] Trial 40 finished with value: 0.6858333333333333 and parameters: {'model__max_depth': 4, 'model__learning_rate': 0.011827816580006298, 'model__subsample': 0.6369307437067941, 'model__colsample_bytree': 0.3179404169247328, 'model__reg_alpha': 0.7588032057197026, 'model__reg_lambda': 1.3693593193617966}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:15,699] Trial 41 finished with value: 0.7369047619047618 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.02084925497427904, 'model__subsample': 0.8669828029445594, 'model__colsample_bytree': 0.19037010356280887, 'model__reg_alpha': 1.9200348524421234, 'model__reg_lambda': 1.6458520115300175}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:18,092] Trial 42 finished with value: 0.6842532467532467 and parameters: {'model__max_depth': 3, 'model__learning_rate': 0.09089725172246371, 'model__subsample': 0.7889759841302185, 'model__colsample_bytree': 0.17531180914044356, 'model__reg_alpha': 1.3574316442557948, 'model__reg_lambda': 1.94129966256074}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:19,770] Trial 43 finished with value: 0.7517532467532467 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.06570035686009419, 'model__subsample': 0.8893376120941875, 'model__colsample_bytree': 0.12503896249256355, 'model__reg_alpha': 1.5975953808792807, 'model__reg_lambda': 2.1737328452217173}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:22,359] Trial 44 finished with value: 0.7859313725490196 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.07597534661353277, 'model__subsample': 0.8194032110792983, 'model__colsample_bytree': 0.21693206926860029, 'model__reg_alpha': 1.1355850316860752, 'model__reg_lambda': 1.6817621896153159}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:24,832] Trial 45 finished with value: 0.8135714285714286 and parameters: {'model__max_depth': 2, 'model__learning_rate': 0.0713911918444198, 'model__subsample': 0.8456536551185366, 'model__colsample_bytree': 0.16220579858667203, 'model__reg_alpha': 2.4002327159238224, 'model__reg_lambda': 2.6987684824514035}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:27,468] Trial 46 finished with value: 0.8147222222222222 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.07226089748781997, 'model__subsample': 0.8480453708783625, 'model__colsample_bytree': 0.1620997704595614, 'model__reg_alpha': 2.460548067754088, 'model__reg_lambda': 2.665299683526001}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:30,596] Trial 47 finished with value: 0.7361694677871149 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.07118589906363919, 'model__subsample': 0.7619266778532958, 'model__colsample_bytree': 0.15146416138336002, 'model__reg_alpha': 2.4664827174778514, 'model__reg_lambda': 2.636865062949701}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:33,759] Trial 48 finished with value: 0.7713045288045287 and parameters: {'model__max_depth': 5, 'model__learning_rate': 0.034326944356011684, 'model__subsample': 0.8802454587666585, 'model__colsample_bytree': 0.1068414963260571, 'model__reg_alpha': 0.18982224663723746, 'model__reg_lambda': 2.92500326535124}. Best is trial 35 with value: 0.8254761904761905.\n",
      "[I 2025-12-12 03:11:37,674] Trial 49 finished with value: 0.6943722943722944 and parameters: {'model__max_depth': 6, 'model__learning_rate': 0.06628048452394172, 'model__subsample': 0.8334609545758258, 'model__colsample_bytree': 0.5487596455271417, 'model__reg_alpha': 2.8432512976071704, 'model__reg_lambda': 2.5591252996797955}. Best is trial 35 with value: 0.8254761904761905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OPTUNA RESULTS =====\n",
      "Best CV PR-AUC (Optuna): 0.8254761904761905\n",
      "\n",
      "Best hyperparameters (Optuna):\n",
      "  model__max_depth: 3\n",
      "  model__learning_rate: 0.02594529453035626\n",
      "  model__subsample: 0.8097992181431611\n",
      "  model__colsample_bytree: 0.16799580159890665\n",
      "  model__reg_alpha: 1.4061736047358249\n",
      "  model__reg_lambda: 1.6099873145029557\n",
      "\n",
      "Saved: optuna_best_params.json\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"model__max_depth\": trial.suggest_int(\"model__max_depth\", 2, 6),\n",
    "        \"model__learning_rate\": trial.suggest_float(\"model__learning_rate\", 0.01, 0.1),\n",
    "        \"model__subsample\": trial.suggest_float(\"model__subsample\", 0.6, 1.0),\n",
    "        \"model__colsample_bytree\": trial.suggest_float(\"model__colsample_bytree\", 0.1, 0.6),\n",
    "        \"model__reg_alpha\": trial.suggest_float(\"model__reg_alpha\", 0.0, 3.0),\n",
    "        \"model__reg_lambda\": trial.suggest_float(\"model__reg_lambda\", 0.0, 3.0),\n",
    "    }\n",
    "\n",
    "    pipe = make_xgb_pipeline(best_iter, scale_pos_weight, random_state=42)\n",
    "    pipe.set_params(**params)\n",
    "\n",
    "    pr_auc = cross_val_score(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring=\"average_precision\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"\\n OPTUNA RESULTS \")\n",
    "print(\"Best CV PR-AUC (Optuna):\", study.best_value)\n",
    "print(\"\\nBest hyperparameters (Optuna):\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "best_optuna_params = study.best_params\n",
    "\n",
    "\n",
    "pd.Series(best_optuna_params).to_json(\"optuna_best_params.json\")\n",
    "print(\"\\nSaved: optuna_best_params.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61cc305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL TEST RESULTS (Optuna XGBoost)\n",
      "TEST PR-AUC: 0.9500\n",
      "\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.84      0.84      0.84        18\n",
      "weighted avg       0.89      0.89      0.89        18\n",
      "\n",
      "Saved: optuna_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, classification_report\n",
    "\n",
    "# combine Train + Val\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# build final Optuna-tuned pipeline\n",
    "final_optuna_pipe = make_xgb_pipeline(best_iter, scale_pos_weight, random_state=42)\n",
    "final_optuna_pipe.set_params(**best_optuna_params)\n",
    "\n",
    "final_optuna_pipe.fit(X_train_full, y_train_full)\n",
    "\n",
    "# test\n",
    "y_test_proba = final_optuna_pipe.predict_proba(X_test)[:, 1]\n",
    "y_test_pred  = final_optuna_pipe.predict(X_test)\n",
    "\n",
    "test_ap = average_precision_score(y_test, y_test_proba)\n",
    "\n",
    "print(\"\\nFINAL TEST RESULTS (Optuna XGBoost)\")\n",
    "print(f\"TEST PR-AUC: {test_ap:.4f}\")\n",
    "print(\"\\nTest Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "optuna_test_results = pd.DataFrame({\n",
    "    \"y_true\": y_test,\n",
    "    \"y_proba_male\": y_test_proba,\n",
    "    \"y_pred\": y_test_pred\n",
    "})\n",
    "optuna_test_results.to_csv(\"optuna_test_predictions.csv\", index=False)\n",
    "print(\"Saved: optuna_test_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78765af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features by |SHAP|:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>num__ENSG00000114374.12</td>\n",
       "      <td>0.248604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>num__ENSG00000099715.14</td>\n",
       "      <td>0.098816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22845</th>\n",
       "      <td>num__ENSG00000227494.2</td>\n",
       "      <td>0.092422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29119</th>\n",
       "      <td>num__ENSG00000241859.6</td>\n",
       "      <td>0.083457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>num__ENSG00000233864.7</td>\n",
       "      <td>0.080106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18783</th>\n",
       "      <td>num__ENSG00000207445.1</td>\n",
       "      <td>0.076641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>num__ENSG00000129824.15</td>\n",
       "      <td>0.073670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13895</th>\n",
       "      <td>num__ENSG00000176728.7</td>\n",
       "      <td>0.046967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>num__ENSG00000012817.15</td>\n",
       "      <td>0.039765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28139</th>\n",
       "      <td>num__ENSG00000238067.1</td>\n",
       "      <td>0.035390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  mean_abs_shap\n",
       "4256   num__ENSG00000114374.12       0.248604\n",
       "2100   num__ENSG00000099715.14       0.098816\n",
       "22845   num__ENSG00000227494.2       0.092422\n",
       "29119   num__ENSG00000241859.6       0.083457\n",
       "26035   num__ENSG00000233864.7       0.080106\n",
       "18783   num__ENSG00000207445.1       0.076641\n",
       "6127   num__ENSG00000129824.15       0.073670\n",
       "13895   num__ENSG00000176728.7       0.046967\n",
       "325    num__ENSG00000012817.15       0.039765\n",
       "28139   num__ENSG00000238067.1       0.035390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Masculinizing features (Optuna):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>male_shap</th>\n",
       "      <th>female_shap</th>\n",
       "      <th>difference_male_minus_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>num__ENSG00000114374.12</td>\n",
       "      <td>0.150770</td>\n",
       "      <td>-0.137022</td>\n",
       "      <td>0.287791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>num__ENSG00000099715.14</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>-0.079356</td>\n",
       "      <td>0.151867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22845</th>\n",
       "      <td>num__ENSG00000227494.2</td>\n",
       "      <td>0.075521</td>\n",
       "      <td>-0.068536</td>\n",
       "      <td>0.144057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29119</th>\n",
       "      <td>num__ENSG00000241859.6</td>\n",
       "      <td>0.054987</td>\n",
       "      <td>-0.065748</td>\n",
       "      <td>0.120736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>num__ENSG00000233864.7</td>\n",
       "      <td>0.053117</td>\n",
       "      <td>-0.065477</td>\n",
       "      <td>0.118594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>num__ENSG00000129824.15</td>\n",
       "      <td>0.061160</td>\n",
       "      <td>-0.042567</td>\n",
       "      <td>0.103727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13895</th>\n",
       "      <td>num__ENSG00000176728.7</td>\n",
       "      <td>0.041030</td>\n",
       "      <td>-0.033796</td>\n",
       "      <td>0.074827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>num__ENSG00000012817.15</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>-0.030914</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28139</th>\n",
       "      <td>num__ENSG00000238067.1</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>-0.025553</td>\n",
       "      <td>0.058925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18783</th>\n",
       "      <td>num__ENSG00000207445.1</td>\n",
       "      <td>0.051218</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.049948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  male_shap  female_shap  \\\n",
       "4256   num__ENSG00000114374.12   0.150770    -0.137022   \n",
       "2100   num__ENSG00000099715.14   0.072511    -0.079356   \n",
       "22845   num__ENSG00000227494.2   0.075521    -0.068536   \n",
       "29119   num__ENSG00000241859.6   0.054987    -0.065748   \n",
       "26035   num__ENSG00000233864.7   0.053117    -0.065477   \n",
       "6127   num__ENSG00000129824.15   0.061160    -0.042567   \n",
       "13895   num__ENSG00000176728.7   0.041030    -0.033796   \n",
       "325    num__ENSG00000012817.15   0.031586    -0.030914   \n",
       "28139   num__ENSG00000238067.1   0.033372    -0.025553   \n",
       "18783   num__ENSG00000207445.1   0.051218     0.001270   \n",
       "\n",
       "       difference_male_minus_female  \n",
       "4256                       0.287791  \n",
       "2100                       0.151867  \n",
       "22845                      0.144057  \n",
       "29119                      0.120736  \n",
       "26035                      0.118594  \n",
       "6127                       0.103727  \n",
       "13895                      0.074827  \n",
       "325                        0.062500  \n",
       "28139                      0.058925  \n",
       "18783                      0.049948  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Feminizing features (Optuna):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>male_shap</th>\n",
       "      <th>female_shap</th>\n",
       "      <th>difference_male_minus_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18850</th>\n",
       "      <td>num__ENSG00000211645.2</td>\n",
       "      <td>-0.005175</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>-0.004424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>num__ENSG00000055957.10</td>\n",
       "      <td>-0.005949</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>-0.005118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>num__ENSG00000253824.1</td>\n",
       "      <td>-0.008272</td>\n",
       "      <td>-0.002975</td>\n",
       "      <td>-0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15352</th>\n",
       "      <td>num__ENSG00000184357.4</td>\n",
       "      <td>-0.004892</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>-0.005609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>num__ENSG00000269416.5</td>\n",
       "      <td>-0.006265</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>-0.006583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40256</th>\n",
       "      <td>num__ENSG00000272554.1</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.006949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29243</th>\n",
       "      <td>num__ENSG00000242259.8</td>\n",
       "      <td>-0.009508</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.009227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17106</th>\n",
       "      <td>num__ENSG00000197980.12</td>\n",
       "      <td>-0.010575</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40956</th>\n",
       "      <td>num__ENSG00000274001.1</td>\n",
       "      <td>-0.007739</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>-0.010703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>num__ENSG00000182256.12</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.013562</td>\n",
       "      <td>-0.015532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  male_shap  female_shap  \\\n",
       "18850   num__ENSG00000211645.2  -0.005175    -0.000751   \n",
       "760    num__ENSG00000055957.10  -0.005949    -0.000831   \n",
       "32533   num__ENSG00000253824.1  -0.008272    -0.002975   \n",
       "15352   num__ENSG00000184357.4  -0.004892     0.000717   \n",
       "38958   num__ENSG00000269416.5  -0.006265     0.000318   \n",
       "40256   num__ENSG00000272554.1  -0.008061    -0.001112   \n",
       "29243   num__ENSG00000242259.8  -0.009508    -0.000281   \n",
       "17106  num__ENSG00000197980.12  -0.010575    -0.000465   \n",
       "40956   num__ENSG00000274001.1  -0.007739     0.002964   \n",
       "14870  num__ENSG00000182256.12  -0.001970     0.013562   \n",
       "\n",
       "       difference_male_minus_female  \n",
       "18850                     -0.004424  \n",
       "760                       -0.005118  \n",
       "32533                     -0.005297  \n",
       "15352                     -0.005609  \n",
       "38958                     -0.006583  \n",
       "40256                     -0.006949  \n",
       "29243                     -0.009227  \n",
       "17106                     -0.010110  \n",
       "40956                     -0.010703  \n",
       "14870                     -0.015532  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pre = final_optuna_pipe.named_steps[\"preprocessor\"]\n",
    "model = final_optuna_pipe.named_steps[\"model\"]\n",
    "\n",
    "X_test_trans = pre.transform(X_test)\n",
    "feature_names = pre.get_feature_names_out()\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_vals = explainer.shap_values(X_test_trans)\n",
    "\n",
    "# binary model returns [class0, class1], use class 1 (male)\n",
    "if isinstance(shap_vals, list):\n",
    "    shap_vals = shap_vals[1]\n",
    "\n",
    "=\n",
    "# Global ranking by mean | SHAP|\n",
    "\n",
    "mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "\n",
    "shap_ranked = (\n",
    "    pd.DataFrame({\"feature\": feature_names, \"mean_abs_shap\": mean_abs_shap})\n",
    "    .sort_values(\"mean_abs_shap\", ascending=False)\n",
    ")\n",
    "\n",
    "shap_ranked.to_csv(\"optuna_shap_global_ranking.csv\", index=False)\n",
    "\n",
    "print(\"\\nTop 10 features by |SHAP|:\")\n",
    "display(shap_ranked.head(10))\n",
    "\n",
    "\n",
    "# directional SHAP: male vs female\n",
    "\n",
    "male_idx = np.where(y_test == 1)[0]\n",
    "female_idx = np.where(y_test == 0)[0]\n",
    "\n",
    "male_shap = shap_vals[male_idx].mean(axis=0)\n",
    "female_shap = shap_vals[female_idx].mean(axis=0)\n",
    "\n",
    "shap_direction = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"male_shap\": male_shap,\n",
    "    \"female_shap\": female_shap,\n",
    "})\n",
    "shap_direction[\"difference_male_minus_female\"] = (\n",
    "    shap_direction[\"male_shap\"] - shap_direction[\"female_shap\"]\n",
    ")\n",
    "\n",
    "shap_direction_sorted = shap_direction.sort_values(\n",
    "    \"difference_male_minus_female\", ascending=False\n",
    ")\n",
    "\n",
    "shap_direction_sorted.to_csv(\"optuna_shap_directional.csv\", index=False)\n",
    "\n",
    "print(\"\\nTop 10 Masculinizing features (Optuna):\")\n",
    "display(shap_direction_sorted.head(10))\n",
    "\n",
    "print(\"\\nTop 10 Feminizing features (Optuna):\")\n",
    "display(shap_direction_sorted.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c801c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== OPTUNA XGB — SEED 0 =====\n",
      "Test PR-AUC (seed 0): 0.7333\n",
      "\n",
      "===== OPTUNA XGB — SEED 1 =====\n",
      "Test PR-AUC (seed 1): 0.6278\n",
      "\n",
      "===== OPTUNA XGB — SEED 2 =====\n",
      "Test PR-AUC (seed 2): 0.8750\n",
      "\n",
      "===== OPTUNA XGB — SEED 3 =====\n",
      "Test PR-AUC (seed 3): 0.5667\n",
      "\n",
      "===== OPTUNA XGB — SEED 4 =====\n",
      "Test PR-AUC (seed 4): 0.9500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>test_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.627778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed   test_ap\n",
       "0     0  0.733333\n",
       "1     1  0.627778\n",
       "2     2  0.875000\n",
       "3     3  0.566667\n",
       "4     4  0.950000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: optuna_seed_metrics.csv\n",
      "Saved: optuna_shap_stability_genes.csv\n",
      "\n",
      "Top 20 stable features by mean |SHAP| (Optuna):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "      <th>std_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>num__ENSG00000114374.12</td>\n",
       "      <td>0.152567</td>\n",
       "      <td>0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15254</th>\n",
       "      <td>num__ENSG00000183878.15</td>\n",
       "      <td>0.152123</td>\n",
       "      <td>0.046781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26035</th>\n",
       "      <td>num__ENSG00000233864.7</td>\n",
       "      <td>0.130063</td>\n",
       "      <td>0.079005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22845</th>\n",
       "      <td>num__ENSG00000227494.2</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>num__ENSG00000012817.15</td>\n",
       "      <td>0.045051</td>\n",
       "      <td>0.029024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42591</th>\n",
       "      <td>num__ENSG00000278847.1</td>\n",
       "      <td>0.042625</td>\n",
       "      <td>0.027995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29119</th>\n",
       "      <td>num__ENSG00000241859.6</td>\n",
       "      <td>0.041711</td>\n",
       "      <td>0.028936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>num__ENSG00000206159.10</td>\n",
       "      <td>0.037985</td>\n",
       "      <td>0.027694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>num__ENSG00000099715.14</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.022351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17312</th>\n",
       "      <td>num__ENSG00000198692.9</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>0.029792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>num__ENSG00000067048.16</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>0.028572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>num__ENSG00000067646.11</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>0.024086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24532</th>\n",
       "      <td>num__ENSG00000230904.1</td>\n",
       "      <td>0.026548</td>\n",
       "      <td>0.049937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13895</th>\n",
       "      <td>num__ENSG00000176728.7</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.025367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>num__ENSG00000131002.11</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.019389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28139</th>\n",
       "      <td>num__ENSG00000238067.1</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.025790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11422</th>\n",
       "      <td>num__ENSG00000165246.14</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.023219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>num__ENSG00000129824.15</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>num__ENSG00000099725.14</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.026606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18614</th>\n",
       "      <td>num__ENSG00000206652.1</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.019551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  mean_abs_shap  std_abs_shap\n",
       "4256   num__ENSG00000114374.12       0.152567      0.057194\n",
       "15254  num__ENSG00000183878.15       0.152123      0.046781\n",
       "26035   num__ENSG00000233864.7       0.130063      0.079005\n",
       "22845   num__ENSG00000227494.2       0.051597      0.041459\n",
       "325    num__ENSG00000012817.15       0.045051      0.029024\n",
       "42591   num__ENSG00000278847.1       0.042625      0.027995\n",
       "29119   num__ENSG00000241859.6       0.041711      0.028936\n",
       "18553  num__ENSG00000206159.10       0.037985      0.027694\n",
       "2100   num__ENSG00000099715.14       0.034362      0.022351\n",
       "17312   num__ENSG00000198692.9       0.033483      0.029792\n",
       "994    num__ENSG00000067048.16       0.032111      0.028572\n",
       "1018   num__ENSG00000067646.11       0.027047      0.024086\n",
       "24532   num__ENSG00000230904.1       0.026548      0.049937\n",
       "13895   num__ENSG00000176728.7       0.023403      0.025367\n",
       "6323   num__ENSG00000131002.11       0.020971      0.019389\n",
       "28139   num__ENSG00000238067.1       0.018600      0.025790\n",
       "11422  num__ENSG00000165246.14       0.017730      0.023219\n",
       "6127   num__ENSG00000129824.15       0.016293      0.017515\n",
       "2101   num__ENSG00000099725.14       0.015819      0.026606\n",
       "18614   num__ENSG00000206652.1       0.015142      0.019551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed_results = []\n",
    "shap_records = []\n",
    "random_states = [0, 1, 2, 3, 4]\n",
    "\n",
    "for seed in random_states:\n",
    "    print(f\"\\n===== OPTUNA XGB — SEED {seed} =====\")\n",
    "\n",
    "\n",
    "    X_train_s, X_temp_s, y_train_s, y_temp_s = train_test_split(\n",
    "        X, y, test_size=0.30, stratify=y, random_state=seed\n",
    "    )\n",
    "    X_val_s, X_test_s, y_val_s, y_test_s = train_test_split(\n",
    "        X_temp_s, y_temp_s, test_size=0.50, stratify=y_temp_s, random_state=seed\n",
    "    )\n",
    "\n",
    "\n",
    "    neg_s = (y_train_s == 0).sum()\n",
    "    pos_s = (y_train_s == 1).sum()\n",
    "    scale_pos_weight_s = neg_s / pos_s\n",
    "\n",
    "    # build Optuna-tuned pipeline for this seed\n",
    "    optuna_seed_pipe = make_xgb_pipeline(best_iter, scale_pos_weight_s, random_state=seed)\n",
    "    optuna_seed_pipe.set_params(**best_optuna_params)\n",
    "\n",
    "\n",
    "    X_train_full_s = pd.concat([X_train_s, X_val_s])\n",
    "    y_train_full_s = pd.concat([y_train_s, y_val_s])\n",
    "\n",
    "    optuna_seed_pipe.fit(X_train_full_s, y_train_full_s)\n",
    "\n",
    "\n",
    "    y_test_proba_s = optuna_seed_pipe.predict_proba(X_test_s)[:, 1]\n",
    "    test_ap_s = average_precision_score(y_test_s, y_test_proba_s)\n",
    "\n",
    "    seed_results.append({\n",
    "        \"seed\": seed,\n",
    "        \"test_ap\": test_ap_s\n",
    "    })\n",
    "    print(f\"Test PR-AUC (seed {seed}): {test_ap_s:.4f}\")\n",
    "\n",
    "\n",
    "    pre_s = optuna_seed_pipe.named_steps[\"preprocessor\"]\n",
    "    model_s = optuna_seed_pipe.named_steps[\"model\"]\n",
    "\n",
    "    X_test_trans_s = pre_s.transform(X_test_s)\n",
    "    feat_names_s = pre_s.get_feature_names_out()\n",
    "\n",
    "    expl_s = shap.TreeExplainer(model_s)\n",
    "    shap_vals_s = expl_s.shap_values(X_test_trans_s)\n",
    "    if isinstance(shap_vals_s, list):\n",
    "        shap_vals_s = shap_vals_s[1]\n",
    "\n",
    "    shap_df_s = pd.DataFrame(shap_vals_s, columns=feat_names_s)\n",
    "    shap_df_s[\"seed\"] = seed\n",
    "    shap_records.append(shap_df_s)\n",
    "\n",
    "\n",
    "seed_df = pd.DataFrame(seed_results)\n",
    "display(seed_df)\n",
    "\n",
    "seed_df.to_csv(\"optuna_seed_metrics.csv\", index=False)\n",
    "print(\"\\nSaved: optuna_seed_metrics.csv\")\n",
    "\n",
    "\n",
    "# SHAP stability across seeds\n",
    "\n",
    "shap_all = pd.concat(shap_records, ignore_index=True)\n",
    "\n",
    "# make sure 2 drop seed col and compute mean SHAP and STDEV SHAP across all seed-samples\n",
    "shap_features_only = shap_all.drop(columns=[\"seed\"])\n",
    "\n",
    "mean_abs_shap = shap_features_only.abs().mean()\n",
    "std_abs_shap = shap_features_only.abs().std()\n",
    "\n",
    "shap_stability = pd.DataFrame({\n",
    "    \"feature\": mean_abs_shap.index,\n",
    "    \"mean_abs_shap\": mean_abs_shap.values,\n",
    "    \"std_abs_shap\": std_abs_shap.values\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "shap_stability.to_csv(\"optuna_shap_stability_genes.csv\", index=False)\n",
    "print(\"Saved: optuna_shap_stability_genes.csv\")\n",
    "\n",
    "print(\"\\nTop 20 stable features by mean |SHAP| (Optuna):\")\n",
    "display(shap_stability.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
